{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkzs7T908tNj",
        "outputId": "705f2064-bda9-4ff0-db36-1fddde6ad10e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: confluent-kafka in e:\\anaconda3\\envs\\aag-talp\\lib\\site-packages (2.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pyspark in e:\\anaconda3\\envs\\aag-talp\\lib\\site-packages (3.5.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in e:\\anaconda3\\envs\\aag-talp\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pymongo in e:\\anaconda3\\envs\\aag-talp\\lib\\site-packages (4.6.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in e:\\anaconda3\\envs\\aag-talp\\lib\\site-packages (from pymongo) (2.4.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: requests in e:\\anaconda3\\envs\\aag-talp\\lib\\site-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\anaconda3\\envs\\aag-talp\\lib\\site-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda3\\envs\\aag-talp\\lib\\site-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\anaconda3\\envs\\aag-talp\\lib\\site-packages (from requests) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda3\\envs\\aag-talp\\lib\\site-packages (from requests) (2023.7.22)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pandas in e:\\anaconda3\\envs\\aag-talp\\lib\\site-packages (2.1.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in e:\\anaconda3\\envs\\aag-talp\\lib\\site-packages (from pandas) (1.26.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\anaconda3\\envs\\aag-talp\\lib\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in e:\\anaconda3\\envs\\aag-talp\\lib\\site-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in e:\\anaconda3\\envs\\aag-talp\\lib\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in e:\\anaconda3\\envs\\aag-talp\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install confluent-kafka\n",
        "%pip install pyspark\n",
        "%pip install pymongo\n",
        "%pip install requests\n",
        "%pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rDocM4tD89Vv"
      },
      "outputs": [],
      "source": [
        "import confluent_kafka as ck\n",
        "import random\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usSvYgLDIBYc",
        "outputId": "3f0b7241-e398-4b18-84bc-27e3c6a225df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%curl` not found.\n"
          ]
        }
      ],
      "source": [
        "%curl ipecho.net/plain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nReXrXwATNjw"
      },
      "source": [
        "# API Infoclimat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orq_52vmUiwN"
      },
      "source": [
        "## Config API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf_ITslMTo-N",
        "outputId": "fbf29a6c-1b58-4f0c-f680-8b4898c90804"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['07117', '000BA', '00049', '000EG', '000ID', '000HB']\n"
          ]
        }
      ],
      "source": [
        "allStations = ['0222', '0220', '0219', '0218', '0217', '0216', '0215', '0213', '0212', '0211', '0208', '0206', '0204', '0203', '0202', '0201', '0200', '0198', '0196', '0193', '0192', '0191', '0190', '0189', '0188', '0186', '0185', '0184', '0183', '0182', '0181', '0180', '0179', '0178', '0172', '0170', '0167', '0166', 'ME153', '0165', '0164', '0162', '0151', '0149', '0147', 'ME152', '0145', '0144', '0142', '0171', '0141', '0139', '0138', 'ME151', '0136', '0134', '0133', '0131', '0129', '0128', '0126', '0125', '0124', '0123', '0122', '0120', '0118', '0117', '0116', '0115', '0114', '0111', '0109', '0108', '0107', '0106', '0105', '0103', '0102', '0101', '0100', '0099', '0098', '0097', '0096', '0095', '0092', '0091', '0093', '0224', '0087', '0086', '0085', '0082', '0079', '0076', '0075', '0074', '0073', '0070', '0068', '0067', '0066', '0065', '0063', '0062', '0061', '0059', '0058', '0055', '0054', '0053', '0052', '0051', '0050', '0048', '0047', '0046', '0044', '0039', '0038', '0037', '0036', '0035', '0032', '0031', '0030', '0029', '0027', '0024', '0023', '0022', '0021', '0016', '0015', '0012', '0011', '0072', '0010', '0009', '0007', '0006', '0005', '0002', '0001', '000ZX', '000ZW', '000ZV', '000ZU', '000ZT', '000ZS', '000ZR', '000ZQ', '000ZP', '0060', '000ZO', '000ZN', '000ZM', '000ZL', '000ZJ', '000ZK', '000ZI', '000ZH', '000ZG', '000ZF', '0205', '000ZE', '000ZB', '000YY', '000YW', '000YU', '0025', '000YO', '000YN', '000YM', '000YL', '000YK', '000YJ', '000YI', '000YH', '000YF', '000YE', '000YB', '000XZ', '000XY', '000XX', '000YX', '000XW', '000XR', '000XP', '000XO', '000XK', '0019', '000XJ', '000XI', '000XH', '000XF', '000YG', '000XE', '000XD', '000XB', '000XA', '000WZ', '000WY', '0013', '000YQ', '0071', '000WX', '000WW', '000WU', '000WN', '000WM', '000WL', '000WK', '000WJ', '000WI', '000WG', '000WF', '000WE', 'ME146', '000WD', '000WA', '000VY', '000VX', '000VW', '000VV', '000VT', '000VP', '000VN', '000VM', '000VL', '000VI', '000VF', '000VE', '000VC', '000UZ', '000UY', '000UW', '000UU', '000UT', '000US', '000UQ', '000UO', '000UN', '000UM', '000UL', '000UK', '000UJ', '000UI', '000UH', '000UF', '000UE', '000UB', '000UA', '000TZ', '000TY', '000TW', '000TS', '000TR', '000TQ', '000VJ', '000TO', '000TM', '000TL', '000TK', '000TJ', '000TG', '000TE', '000TD', '000TC', '000TB', '000TA', '000SZ', '000SY', '000SW', '000SU', '000ST', '000SS', '000SR', '000SP', '000SL', '000SK', '000SG', '000SF', '000SE', '000SD', '000SC', '000SB', '000RZ', '000RY', '000RX', '000RT', '000RS', '000RQ', '000RO', '000RM', '000RL', '000RK', '000RJ', '000RI', '000TU', '000RH', '000UC', '000SM', '000UD', '000TN', '000RG', '000RF', '000RE', '000RD', '000RC', '000RA', '000QZ', '000QY', '000RB', '000QX', '000QW', '000QT', '000QS', '000QR', '000QO', '000QN', '000QM', '000QJ', '000QI', '000QH', '000QG', '000QE', '000QD', '000QC', '000QB', '000QA', '000PZ', '000PY', '000PW', '000QF', '000PU', '000PT', '000PS', '000PQ', '000PP', '000PN', '000PM', '000PX', '000PL', '000PJ', '000PI', '000PH', '000PG', '000PA', '000OX', '000OZ', '000OU', '000OS', '000OR', '000OQ', '000OP', '000ON', '000OW', '000OM', '000OK', '000OJ', '000OI', '000OH', '000OG', 'ME139', '000OB', '000OA', '000NZ', '000NX', '000NW', '000NU', '000NT', '000NR', '000NQ', '000NM', '000NK', '000NJ', '000NI', '000NG', '000ND', '000NC', '000NB', '000MZ', '000MW', '000MV', '000MY', '000MS', '000MR', '000MQ', 'ME135', 'ME134', 'ME132', 'ME131', 'ME130', 'ME128', 'ME137', 'ME125', 'ME123', 'ME126', 'ME121', 'ME124', 'ME119', 'ME118', 'ME129', 'ME120', 'ME115', 'ME113', 'ME116', 'ME114', 'ME117', 'ME111', 'ME112', 'ME108', 'ME106', 'ME110', 'ME105', 'ME104', 'ME103', 'ME102', 'ME109', 'ME099', 'ME098', 'ME052', 'ME048', 'ME047', 'ME046', 'ME045', 'ME044', 'ME043', 'ME042', 'ME040', 'ME039', 'ME038', 'ME036', 'ME035', 'ME034', 'ME033', 'ME032', 'ME031', 'ME030', 'ME029', 'ME028', 'ME027', 'ME026', 'ME024', 'ME023', 'ME022', 'ME021', 'ME020', 'ME019', 'ME017', 'ME016', 'ME013', 'ME012', 'ME011', 'ME010', 'ME009', 'ME007', 'ME006', 'ME005', 'ME004', 'ME051', 'ME050', 'ME001', '000MP', 'ME014', '000MO', '000MN', '000ML', '000MK', '000MJ', '000MI', '000MT', '000MG', '000MF', '000MD', '000MB', '000MA', '000LZ', '000LY', '000LV', '000LU', '000LS', '000LR', '000LQ', '000LP', '000LO', '000LM', '000IK', '000IF', '000ID', '000IC', '000IB', '000IA', '000HT', '000HS', '000HO', '000HM', '000HJ', '000HH', '000HF', '000HB', '000GU', '000GT', '000GS', '000GR', '000GQ', '000GP', '000HC', '000GO', '000GN', '000GL', '000GK', '000GJ', '000GI', '000GF', '000GM', '000GC', '000FZ', '000FY', '000FX', '000FW', '000GB', '000FV', '000FU', '000FT', '000FS', '000FR', '000FP', '000FO', '000FN', '000FM', '000FL', '000FK', '000FI', '000FG', '000FE', '000FD', '000FC', '000FB', '000OT', '000FA', '000EW', '000EV', '000EU', '000EQ', '000EN', '000ET', '000II', '000EK', '000EI', '000EP', '000EG', '000ED', '000EC', '000EB', '000DZ', '000DX', '000DV', '000DS', '000DR', '000DQ', '000DP', '000HR', '000DN', '000DM', '000DJ', '000DI', '000DH', '000DF', '000DE', '000DD', '000DC', '000DB', '000CZ', '000CY', '000CX', '000CW', '000CV', '000CT', '000CR', '000CP', '000CO', '000CN', '000CM', '000CK', '000CJ', '000CI', '000CF', '000CE', '000CD', '000CC', '000CA', '000BZ', '000BY', '000BX', '000BV', '000BS', '000BO', '000BM', '000BI', '000BN', '000BG', '000BQ', '000BE', '000BB', '000BA', '000AX', '000AV', '000AS', '000AL', '000AK', '000AJ', '000AI', '000AH', '000AF', '000AD', '000AC', '000AB', '000AA', '000Z9', '000Z7', '000Z6', '000Z4', '000Z1', '000Z0', '000Y5', '000Y3', '000VB', '000AU', '000X8', '000X6', '000X5', '000X4', '000X3', '000X2', '000X1', '000X0', '000W9', '000W8', '000W7', '000Y4', '000W6', '000W5', '000DA', '000W2', '000W1', '000V6', '0132', '000V4', '000V3', '000V2', '000V0', '000U7', '000U6', '000U4', '000U3', '000QU', '000U1', '000U0', '000T8', '000T9', '000T6', '000T5', '000T3', '000T1', '000T0', '000S9', '000S8', '000S6', '000S3', '000S2', '000S4', '000S1', '000S0', '000R6', '000R5', '000R4', '000R3', '000R2', '000R1', '000Q8', '000Q6', '000Q4', '000Q2', '000P9', '000P8', '000P6', '000P4', '000P2', '000P1', '000O9', '000O8', '000O7', '000O5', '000O4', '000O3', '000O2', '000N9', '000N4', '000N3', '000Q7', '000M7', '000M6', '000M4', '000M2', '000L9', '000L7', '000L5', '000L3', '000Q3', '000P7', '000L2', '000L1', '000K7', '000K6', '000K5', '000K4', '000K2', '000K1', '000K0', '000J9', '000J8', '000J4', '000I7', '000J2', '000I9', '000I6', '000I5', '000I4', '000E8', '000E7', '000K3', '000E2', '000E0', '000I2', '000I1', '000H9', '000H8', '000H6', '000H4', '000G7', '000G6', '000G4', '000G3', '000G2', '000G1', '000F8', '000F7', '000F4', '000D8', '000F3', '000BP', '000D5', '000D2', '000D3', '000C9', '000C6', '000C5', '000C7', '000B8', '000B9', '000C1', '000C0', '000B5', '000B6', '000B4', '000B3', '000B0', '000A9', '000A5', '000A6', '000A3', '000A1', '00099', '00098', '00096', '00095', '00094', '00092', '00091', '00089', '00088', '00086', '00080', '00081', '00076', '00074', '00072', '00070', '00065', '00061', '00063', '00060', '00053', '00059', '00054', '00052', '00051', '00049', '00047', '00042', '00041', '00038', '00035', '00033', '00032', '00029', '00025', '00023', '00001', '00018', '00014', '00010', '00009', '000J1', '000VQ', '00004', '00002', 'VENTOUX', '07747', '07650', '07643', '07630', '07627', '07621', '07607', '07591', '07577', '07558', '07535', '07510', '07481', '07471', '07460', '07434', '07335', '07314', '07299', '07280', '07255', '07240', '07222', '07207', '07190', '07181', '07168', '07149', '07139', '07130', '07117', '07110', '07070', '07037', '07027', '07020', '07015', '07005', '000WT', '0113', '0056', '0008', '000TP', '000OO', 'ME107', 'ME025', 'ME008', '000EO', '000CL', '000BU', '000Y9', '000X9', '000U9', '000Q9', '000N6', '000M9', '000M8', '000L4', '000J6', '000J0', '00093', '00075', '00057', '00003', '07661', '000BL', '000C4', '000NP', '000AY', 'ME003', '000Z8', '0148', '000NH', '000V7', '000SH', '000EF', '000WB', 'ME101', '0175', '0174', '0146', 'CAYOLLE', 'ENTRAUNES', '0033', '000ZC', '000YZ', '000XN', '000TX', '000SN', '000PK', '000NL', 'ME015', '000HL', '000HD', '000GH', '000GG', '000GD', '07690', '000UX', '000QV', '000U2', '000ZA', '000SX', '0014', 'ME136', 'ME049', '000XM', '000MX', '000Y1', '000EH', '000YD', '000NF', 'ME138', '000PO', '0084', '0069', '000SO', '000AE', '000N5', '00027', '00015', '07790', '000RN', '0194', '07761', 'ME018', 'ME057', '000CU']\n",
        "#function to get random stations in a range as parameter\n",
        "def get_random_stations(n):\n",
        "  return random.sample(allStations, n)\n",
        "print(get_random_stations(6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dqbBjBSQUkaS"
      },
      "outputs": [],
      "source": [
        "api_token = 'cELguLzjiB2WDGMIacgzE7cXSmAPIw1MlSEi53H68FxA7bhkqFdcA'\n",
        "stations = get_random_stations(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLuiDUV4TPxh"
      },
      "source": [
        "## Creation de l'url d'API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7btMTiTR-KpV"
      },
      "outputs": [],
      "source": [
        "\n",
        "import requests\n",
        "import csv\n",
        "from io import StringIO\n",
        "\n",
        "def build_api_url(start, end, token, stations):\n",
        "    base_url = 'https://www.infoclimat.fr/opendata/?method=get&format=csv&'\n",
        "    stations_param = '&'.join([f'stations[]={station}' for station in stations])\n",
        "    date_param = f'start={start}&end={end}'\n",
        "    token_param = f'token={token}'\n",
        "    api_url = f'{base_url}{stations_param}&{date_param}&{token_param}'\n",
        "    print(api_url)\n",
        "    return api_url\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD47BeL5TUL3"
      },
      "source": [
        "## Appel d'API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oQkmtdE_GcD6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def call_api(api_url):\n",
        "  # Make a GET request to the API\n",
        "  headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "  columns_to_exclude = ['pression', 'humidite','point_de_rosee','vent_rafales','vent_direction','pluie_3h']\n",
        "  response = requests.get(api_url, headers=headers)\n",
        "  response.encoding='utf-8-sig'\n",
        "  #time.sleep()\n",
        "  data_df = pd.DataFrame()\n",
        "  # Check if the request was successful (status code 200)\n",
        "  if response.status_code == 200:\n",
        "        try:\n",
        "            # Parse the CSV data using the csv module\n",
        "            comment_lines = []\n",
        "            for line in StringIO(response.text):\n",
        "                if line.startswith('#'):\n",
        "                    comment_data = line.strip().split(':', 1) \n",
        "                    comment_lines.append(comment_data)\n",
        "\n",
        "            # Convert the list of comment lines to a DataFrame\n",
        "            global metadata_df \n",
        "            metadata_df = pd.DataFrame(comment_lines, columns=['id_station', 'nom_station'])\n",
        "            # Read the rest of the file for data, specifying the ';' separator\n",
        "            data_df = pd.read_csv(StringIO(response.text), na_values=['nan'], comment='#', on_bad_lines='skip', encoding='utf-8-sig', sep=';', skiprows=metadata_df.shape[0], header=[0, 1])\n",
        "            data_df = data_df.drop(columns_to_exclude, axis=1)\n",
        "            time.sleep(5)\n",
        "        except Exception as e:\n",
        "            print(f\"Error decoding CSV: {e}\")\n",
        "  else:\n",
        "      # If the request was not successful, print the error code\n",
        "      print(f\"Error: {response.status_code}\")\n",
        "  #display(df)\n",
        "  return data_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8b2TBw7U8v0"
      },
      "source": [
        "### Test Appel Api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "ZiZUbGBlU-EV",
        "outputId": "7487da52-73b8-48d8-aac7-4ef1574fdf2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://www.infoclimat.fr/opendata/?method=get&format=csv&stations[]=ME042&stations[]=000C4&stations[]=0122&stations[]=000G7&stations[]=ME033&stations[]=000YW&stations[]=000T3&stations[]=000TJ&stations[]=000P8&stations[]=000UF&stations[]=000UK&stations[]=000DI&stations[]=000WT&stations[]=00033&stations[]=000ZK&stations[]=000WF&stations[]=07070&stations[]=000Y1&stations[]=0174&stations[]=0071&stations[]=000UM&stations[]=000EN&stations[]=00054&stations[]=00086&stations[]=000GB&stations[]=000SU&stations[]=000SC&stations[]=000BO&stations[]=000HJ&stations[]=ME131&stations[]=000UC&stations[]=000OG&stations[]=0048&stations[]=000GP&stations[]=ME098&stations[]=07627&stations[]=07335&stations[]=ME117&stations[]=000GT&stations[]=000WE&stations[]=0222&stations[]=ME032&stations[]=000PS&stations[]=000LY&stations[]=07661&stations[]=0068&stations[]=0055&stations[]=0151&stations[]=0206&stations[]=ME102&stations[]=000C7&stations[]=000VQ&stations[]=000ZX&stations[]=000CW&stations[]=000TL&stations[]=0037&stations[]=000F3&stations[]=000G2&stations[]=000K2&stations[]=ME119&stations[]=000Z9&stations[]=000Y5&stations[]=000ST&stations[]=000DP&stations[]=000IC&stations[]=000A1&stations[]=ME034&stations[]=07761&stations[]=0182&stations[]=000HH&stations[]=000ZU&stations[]=000NG&stations[]=000RX&stations[]=VENTOUX&stations[]=000BZ&stations[]=ME052&stations[]=000V2&stations[]=00047&stations[]=000XJ&stations[]=000PU&stations[]=0204&stations[]=000V0&stations[]=07110&stations[]=0147&stations[]=000DQ&stations[]=ME011&stations[]=000N3&stations[]=000NM&stations[]=000OM&stations[]=000QT&stations[]=07280&stations[]=000X2&stations[]=000YN&stations[]=000RL&stations[]=0213&stations[]=000AY&stations[]=000RE&stations[]=ME020&stations[]=0069&stations[]=000CT&stations[]=000BV&start=2022-11-29&end=2022-11-30&token=cELguLzjiB2WDGMIacgzE7cXSmAPIw1MlSEi53H68FxA7bhkqFdcA\n",
            "Error decoding CSV: 'pluie_3h'\n",
            "CSV Data:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Julian\\AppData\\Local\\Temp\\ipykernel_9496\\1021768753.py:26: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
            "  data_df = data_df.drop(columns_to_exclude, axis=1)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>station_id</th>\n",
              "      <th>dh_utc</th>\n",
              "      <th>temperature</th>\n",
              "      <th>pression</th>\n",
              "      <th>humidite</th>\n",
              "      <th>point_de_rosee</th>\n",
              "      <th>vent_moyen</th>\n",
              "      <th>vent_rafales</th>\n",
              "      <th>vent_direction</th>\n",
              "      <th>pluie_1h</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>station_id</th>\n",
              "      <th>dh_utc</th>\n",
              "      <th>degC</th>\n",
              "      <th>hPa</th>\n",
              "      <th>%</th>\n",
              "      <th>degC</th>\n",
              "      <th>km/h</th>\n",
              "      <th>km/h</th>\n",
              "      <th>deg</th>\n",
              "      <th>mm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>00033</th>\n",
              "      <td>2022-11-29 00:00:00</td>\n",
              "      <td>5.3</td>\n",
              "      <td>1015.4</td>\n",
              "      <td>92.0</td>\n",
              "      <td>4.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>279.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00033</th>\n",
              "      <td>2022-11-29 00:10:00</td>\n",
              "      <td>5.2</td>\n",
              "      <td>1015.3</td>\n",
              "      <td>92.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>273.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00033</th>\n",
              "      <td>2022-11-29 00:30:00</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1015.5</td>\n",
              "      <td>92.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>285.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00033</th>\n",
              "      <td>2022-11-29 00:40:00</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1015.4</td>\n",
              "      <td>92.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>285.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00033</th>\n",
              "      <td>2022-11-29 01:00:00</td>\n",
              "      <td>4.7</td>\n",
              "      <td>1015.3</td>\n",
              "      <td>92.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>261.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>VENTOUX</th>\n",
              "      <td>2022-11-30 19:00:00</td>\n",
              "      <td>-2.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19.8</td>\n",
              "      <td>23.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>VENTOUX</th>\n",
              "      <td>2022-11-30 20:00:00</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.4</td>\n",
              "      <td>22.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>VENTOUX</th>\n",
              "      <td>2022-11-30 21:00:00</td>\n",
              "      <td>-3.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.2</td>\n",
              "      <td>18.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>VENTOUX</th>\n",
              "      <td>2022-11-30 22:00:00</td>\n",
              "      <td>-3.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.4</td>\n",
              "      <td>21.2</td>\n",
              "      <td>146.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>VENTOUX</th>\n",
              "      <td>2022-11-30 23:00:00</td>\n",
              "      <td>-3.4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>17.6</td>\n",
              "      <td>151.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14539 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  station_id dh_utc temperature pression humidite  \\\n",
              "                  station_id dh_utc        degC      hPa        %   \n",
              "00033    2022-11-29 00:00:00    5.3      1015.4     92.0      4.1   \n",
              "00033    2022-11-29 00:10:00    5.2      1015.3     92.0      4.0   \n",
              "00033    2022-11-29 00:30:00    5.1      1015.5     92.0      3.9   \n",
              "00033    2022-11-29 00:40:00    4.9      1015.4     92.0      3.8   \n",
              "00033    2022-11-29 01:00:00    4.7      1015.3     92.0      3.5   \n",
              "...                      ...    ...         ...      ...      ...   \n",
              "VENTOUX  2022-11-30 19:00:00   -2.7         NaN      NaN      NaN   \n",
              "VENTOUX  2022-11-30 20:00:00   -3.0         NaN      NaN      NaN   \n",
              "VENTOUX  2022-11-30 21:00:00   -3.3         NaN      NaN      NaN   \n",
              "VENTOUX  2022-11-30 22:00:00   -3.3         NaN      NaN      NaN   \n",
              "VENTOUX  2022-11-30 23:00:00   -3.4         NaN      NaN      NaN   \n",
              "\n",
              "        point_de_rosee vent_moyen vent_rafales vent_direction pluie_1h  \n",
              "                  degC       km/h         km/h            deg       mm  \n",
              "00033              0.0        NaN        279.0            0.0      0.0  \n",
              "00033              0.0        NaN        273.0            NaN      NaN  \n",
              "00033              0.0        NaN        285.0            NaN      NaN  \n",
              "00033              0.0        NaN        285.0            NaN      NaN  \n",
              "00033              0.0        NaN        261.0            0.0      0.0  \n",
              "...                ...        ...          ...            ...      ...  \n",
              "VENTOUX           19.8       23.0        135.0            NaN      NaN  \n",
              "VENTOUX           14.4       22.0        142.0            NaN      NaN  \n",
              "VENTOUX           16.2       18.0        144.0            NaN      NaN  \n",
              "VENTOUX           14.4       21.2        146.0            NaN      NaN  \n",
              "VENTOUX           13.0       17.6        151.0            NaN      NaN  \n",
              "\n",
              "[14539 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_station</th>\n",
              "      <th>nom_station</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td># METADATA</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td># 00033</td>\n",
              "      <td>Véretz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td># 00047</td>\n",
              "      <td>Plabennec</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td># 00054</td>\n",
              "      <td>Corny-sur-Moselle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td># 00086</td>\n",
              "      <td>Saint-Malo-des-Trois-Fontaines</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td># ME119</td>\n",
              "      <td>[MAE] Cité Scolaire Alfred Kastler - STENAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td># ME131</td>\n",
              "      <td>[MAE] Collège Lavoisier - AUCHEL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td># VENTOUX</td>\n",
              "      <td>Mont-Ventoux (sommet)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td># Source</td>\n",
              "      <td>www.infoclimat.fr/MeteoFrance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td># Licence Ouverte/Open License</td>\n",
              "      <td>http://wiki.data.gouv.fr/images/9/9d/Licence_...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>89 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        id_station  \\\n",
              "0                       # METADATA   \n",
              "1                          # 00033   \n",
              "2                          # 00047   \n",
              "3                          # 00054   \n",
              "4                          # 00086   \n",
              "..                             ...   \n",
              "84                         # ME119   \n",
              "85                         # ME131   \n",
              "86                       # VENTOUX   \n",
              "87                        # Source   \n",
              "88  # Licence Ouverte/Open License   \n",
              "\n",
              "                                          nom_station  \n",
              "0                                                      \n",
              "1                                              Véretz  \n",
              "2                                           Plabennec  \n",
              "3                                   Corny-sur-Moselle  \n",
              "4                      Saint-Malo-des-Trois-Fontaines  \n",
              "..                                                ...  \n",
              "84        [MAE] Cité Scolaire Alfred Kastler - STENAY  \n",
              "85                   [MAE] Collège Lavoisier - AUCHEL  \n",
              "86                              Mont-Ventoux (sommet)  \n",
              "87                      www.infoclimat.fr/MeteoFrance  \n",
              "88   http://wiki.data.gouv.fr/images/9/9d/Licence_...  \n",
              "\n",
              "[89 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Example usage:\n",
        "start_date = '2022-11-29'\n",
        "end_date = '2022-11-30'\n",
        "stations.append('000BV')\n",
        "api_url = build_api_url(start_date, end_date, api_token, stations)\n",
        "csv_data = call_api(api_url)\n",
        "\n",
        "print(\"CSV Data:\")\n",
        "display(csv_data)\n",
        "display(metadata_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFhIMDbbTXAc"
      },
      "source": [
        "## Recuperer les intervalles de semaines de 1 mois precis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jqmiNOeTAqa",
        "outputId": "154a3460-3257-46b4-d38a-ce66824c4d32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start and finish dates for 2019-11: [['2019-11-01', '2019-11-07'], ['2019-11-08', '2019-11-14'], ['2019-11-15', '2019-11-21'], ['2019-11-22', '2019-11-28'], ['2019-11-29', '2019-11-30']]\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime, timedelta, date\n",
        "import calendar\n",
        "\n",
        "def get_week_intervals(year, month):\n",
        "    first_day = datetime(year, month, 1)\n",
        "    _, last_day_of_month = calendar.monthrange(year, month)\n",
        "    last_day = datetime(year, month, last_day_of_month)\n",
        "    num_weeks = (last_day - first_day).days // 7 + 1\n",
        "    start_and_finish_dates = []\n",
        "\n",
        "    for week in range(num_weeks):\n",
        "        start_date = first_day + timedelta(days=week * 7)\n",
        "        finish_date = min(first_day + timedelta(days=(week + 1) * 7 - 1), last_day)\n",
        "        start_and_finish_dates.append([start_date.strftime('%Y-%m-%d'), finish_date.strftime('%Y-%m-%d')])\n",
        "\n",
        "    return start_and_finish_dates\n",
        "\n",
        "# Example usage:\n",
        "year = 2019\n",
        "month = 11\n",
        "start_and_finish_dates = get_week_intervals(year, month)\n",
        "print(f'Start and finish dates for {year}-{month:02d}: {start_and_finish_dates}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkfkyA0UWovE"
      },
      "source": [
        "## Recuperer dataframe des donnes meteo d'un mois precis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AzM8oXlWoTF",
        "outputId": "7ceb1012-07a0-4ff9-d3de-57720bf89a9c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "def get_data_for_month(year, month, token, stations):\n",
        "    # Get start and finish dates\n",
        "    start_and_finish_dates = get_week_intervals(year, month)\n",
        "    # Initialize a list to store dataframes\n",
        "    dataframes = []\n",
        "    # Iterate through start and finish date pairs\n",
        "    for start_date, finish_date in start_and_finish_dates:\n",
        "        #print(start_date)\n",
        "        #print(finish_date)\n",
        "        # Build API URL\n",
        "        api_url = build_api_url(start_date, finish_date, token, stations)\n",
        "        # Call API to get dataframe\n",
        "        dataframe = call_api(api_url)\n",
        "        if not dataframe.empty:\n",
        "            dataframes.append(dataframe)\n",
        "    # Concatenate dataframes\n",
        "    concatenated_dataframe = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "    return concatenated_dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test recuperation de données sur 1 mois"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://www.infoclimat.fr/opendata/?method=get&format=csv&stations[]=ME042&stations[]=000C4&stations[]=0122&stations[]=000G7&stations[]=ME033&stations[]=000YW&stations[]=000T3&stations[]=000TJ&stations[]=000P8&stations[]=000UF&stations[]=000UK&stations[]=000DI&stations[]=000WT&stations[]=00033&stations[]=000ZK&stations[]=000WF&stations[]=07070&stations[]=000Y1&stations[]=0174&stations[]=0071&stations[]=000UM&stations[]=000EN&stations[]=00054&stations[]=00086&stations[]=000GB&stations[]=000SU&stations[]=000SC&stations[]=000BO&stations[]=000HJ&stations[]=ME131&stations[]=000UC&stations[]=000OG&stations[]=0048&stations[]=000GP&stations[]=ME098&stations[]=07627&stations[]=07335&stations[]=ME117&stations[]=000GT&stations[]=000WE&stations[]=0222&stations[]=ME032&stations[]=000PS&stations[]=000LY&stations[]=07661&stations[]=0068&stations[]=0055&stations[]=0151&stations[]=0206&stations[]=ME102&stations[]=000C7&stations[]=000VQ&stations[]=000ZX&stations[]=000CW&stations[]=000TL&stations[]=0037&stations[]=000F3&stations[]=000G2&stations[]=000K2&stations[]=ME119&stations[]=000Z9&stations[]=000Y5&stations[]=000ST&stations[]=000DP&stations[]=000IC&stations[]=000A1&stations[]=ME034&stations[]=07761&stations[]=0182&stations[]=000HH&stations[]=000ZU&stations[]=000NG&stations[]=000RX&stations[]=VENTOUX&stations[]=000BZ&stations[]=ME052&stations[]=000V2&stations[]=00047&stations[]=000XJ&stations[]=000PU&stations[]=0204&stations[]=000V0&stations[]=07110&stations[]=0147&stations[]=000DQ&stations[]=ME011&stations[]=000N3&stations[]=000NM&stations[]=000OM&stations[]=000QT&stations[]=07280&stations[]=000X2&stations[]=000YN&stations[]=000RL&stations[]=0213&stations[]=000AY&stations[]=000RE&stations[]=ME020&stations[]=0069&stations[]=000CT&stations[]=000BV&start=2019-11-01&end=2019-11-07&token=cELguLzjiB2WDGMIacgzE7cXSmAPIw1MlSEi53H68FxA7bhkqFdcA\n",
            "Error: 504\n",
            "https://www.infoclimat.fr/opendata/?method=get&format=csv&stations[]=ME042&stations[]=000C4&stations[]=0122&stations[]=000G7&stations[]=ME033&stations[]=000YW&stations[]=000T3&stations[]=000TJ&stations[]=000P8&stations[]=000UF&stations[]=000UK&stations[]=000DI&stations[]=000WT&stations[]=00033&stations[]=000ZK&stations[]=000WF&stations[]=07070&stations[]=000Y1&stations[]=0174&stations[]=0071&stations[]=000UM&stations[]=000EN&stations[]=00054&stations[]=00086&stations[]=000GB&stations[]=000SU&stations[]=000SC&stations[]=000BO&stations[]=000HJ&stations[]=ME131&stations[]=000UC&stations[]=000OG&stations[]=0048&stations[]=000GP&stations[]=ME098&stations[]=07627&stations[]=07335&stations[]=ME117&stations[]=000GT&stations[]=000WE&stations[]=0222&stations[]=ME032&stations[]=000PS&stations[]=000LY&stations[]=07661&stations[]=0068&stations[]=0055&stations[]=0151&stations[]=0206&stations[]=ME102&stations[]=000C7&stations[]=000VQ&stations[]=000ZX&stations[]=000CW&stations[]=000TL&stations[]=0037&stations[]=000F3&stations[]=000G2&stations[]=000K2&stations[]=ME119&stations[]=000Z9&stations[]=000Y5&stations[]=000ST&stations[]=000DP&stations[]=000IC&stations[]=000A1&stations[]=ME034&stations[]=07761&stations[]=0182&stations[]=000HH&stations[]=000ZU&stations[]=000NG&stations[]=000RX&stations[]=VENTOUX&stations[]=000BZ&stations[]=ME052&stations[]=000V2&stations[]=00047&stations[]=000XJ&stations[]=000PU&stations[]=0204&stations[]=000V0&stations[]=07110&stations[]=0147&stations[]=000DQ&stations[]=ME011&stations[]=000N3&stations[]=000NM&stations[]=000OM&stations[]=000QT&stations[]=07280&stations[]=000X2&stations[]=000YN&stations[]=000RL&stations[]=0213&stations[]=000AY&stations[]=000RE&stations[]=ME020&stations[]=0069&stations[]=000CT&stations[]=000BV&start=2019-11-08&end=2019-11-14&token=cELguLzjiB2WDGMIacgzE7cXSmAPIw1MlSEi53H68FxA7bhkqFdcA\n",
            "Error: 504\n",
            "https://www.infoclimat.fr/opendata/?method=get&format=csv&stations[]=ME042&stations[]=000C4&stations[]=0122&stations[]=000G7&stations[]=ME033&stations[]=000YW&stations[]=000T3&stations[]=000TJ&stations[]=000P8&stations[]=000UF&stations[]=000UK&stations[]=000DI&stations[]=000WT&stations[]=00033&stations[]=000ZK&stations[]=000WF&stations[]=07070&stations[]=000Y1&stations[]=0174&stations[]=0071&stations[]=000UM&stations[]=000EN&stations[]=00054&stations[]=00086&stations[]=000GB&stations[]=000SU&stations[]=000SC&stations[]=000BO&stations[]=000HJ&stations[]=ME131&stations[]=000UC&stations[]=000OG&stations[]=0048&stations[]=000GP&stations[]=ME098&stations[]=07627&stations[]=07335&stations[]=ME117&stations[]=000GT&stations[]=000WE&stations[]=0222&stations[]=ME032&stations[]=000PS&stations[]=000LY&stations[]=07661&stations[]=0068&stations[]=0055&stations[]=0151&stations[]=0206&stations[]=ME102&stations[]=000C7&stations[]=000VQ&stations[]=000ZX&stations[]=000CW&stations[]=000TL&stations[]=0037&stations[]=000F3&stations[]=000G2&stations[]=000K2&stations[]=ME119&stations[]=000Z9&stations[]=000Y5&stations[]=000ST&stations[]=000DP&stations[]=000IC&stations[]=000A1&stations[]=ME034&stations[]=07761&stations[]=0182&stations[]=000HH&stations[]=000ZU&stations[]=000NG&stations[]=000RX&stations[]=VENTOUX&stations[]=000BZ&stations[]=ME052&stations[]=000V2&stations[]=00047&stations[]=000XJ&stations[]=000PU&stations[]=0204&stations[]=000V0&stations[]=07110&stations[]=0147&stations[]=000DQ&stations[]=ME011&stations[]=000N3&stations[]=000NM&stations[]=000OM&stations[]=000QT&stations[]=07280&stations[]=000X2&stations[]=000YN&stations[]=000RL&stations[]=0213&stations[]=000AY&stations[]=000RE&stations[]=ME020&stations[]=0069&stations[]=000CT&stations[]=000BV&start=2019-11-15&end=2019-11-21&token=cELguLzjiB2WDGMIacgzE7cXSmAPIw1MlSEi53H68FxA7bhkqFdcA\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Julian\\AppData\\Local\\Temp\\ipykernel_9496\\1021768753.py:26: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
            "  data_df = data_df.drop(columns_to_exclude, axis=1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error decoding CSV: 'pluie_3h'\n",
            "https://www.infoclimat.fr/opendata/?method=get&format=csv&stations[]=ME042&stations[]=000C4&stations[]=0122&stations[]=000G7&stations[]=ME033&stations[]=000YW&stations[]=000T3&stations[]=000TJ&stations[]=000P8&stations[]=000UF&stations[]=000UK&stations[]=000DI&stations[]=000WT&stations[]=00033&stations[]=000ZK&stations[]=000WF&stations[]=07070&stations[]=000Y1&stations[]=0174&stations[]=0071&stations[]=000UM&stations[]=000EN&stations[]=00054&stations[]=00086&stations[]=000GB&stations[]=000SU&stations[]=000SC&stations[]=000BO&stations[]=000HJ&stations[]=ME131&stations[]=000UC&stations[]=000OG&stations[]=0048&stations[]=000GP&stations[]=ME098&stations[]=07627&stations[]=07335&stations[]=ME117&stations[]=000GT&stations[]=000WE&stations[]=0222&stations[]=ME032&stations[]=000PS&stations[]=000LY&stations[]=07661&stations[]=0068&stations[]=0055&stations[]=0151&stations[]=0206&stations[]=ME102&stations[]=000C7&stations[]=000VQ&stations[]=000ZX&stations[]=000CW&stations[]=000TL&stations[]=0037&stations[]=000F3&stations[]=000G2&stations[]=000K2&stations[]=ME119&stations[]=000Z9&stations[]=000Y5&stations[]=000ST&stations[]=000DP&stations[]=000IC&stations[]=000A1&stations[]=ME034&stations[]=07761&stations[]=0182&stations[]=000HH&stations[]=000ZU&stations[]=000NG&stations[]=000RX&stations[]=VENTOUX&stations[]=000BZ&stations[]=ME052&stations[]=000V2&stations[]=00047&stations[]=000XJ&stations[]=000PU&stations[]=0204&stations[]=000V0&stations[]=07110&stations[]=0147&stations[]=000DQ&stations[]=ME011&stations[]=000N3&stations[]=000NM&stations[]=000OM&stations[]=000QT&stations[]=07280&stations[]=000X2&stations[]=000YN&stations[]=000RL&stations[]=0213&stations[]=000AY&stations[]=000RE&stations[]=ME020&stations[]=0069&stations[]=000CT&stations[]=000BV&start=2019-11-22&end=2019-11-28&token=cELguLzjiB2WDGMIacgzE7cXSmAPIw1MlSEi53H68FxA7bhkqFdcA\n",
            "Error: 504\n",
            "https://www.infoclimat.fr/opendata/?method=get&format=csv&stations[]=ME042&stations[]=000C4&stations[]=0122&stations[]=000G7&stations[]=ME033&stations[]=000YW&stations[]=000T3&stations[]=000TJ&stations[]=000P8&stations[]=000UF&stations[]=000UK&stations[]=000DI&stations[]=000WT&stations[]=00033&stations[]=000ZK&stations[]=000WF&stations[]=07070&stations[]=000Y1&stations[]=0174&stations[]=0071&stations[]=000UM&stations[]=000EN&stations[]=00054&stations[]=00086&stations[]=000GB&stations[]=000SU&stations[]=000SC&stations[]=000BO&stations[]=000HJ&stations[]=ME131&stations[]=000UC&stations[]=000OG&stations[]=0048&stations[]=000GP&stations[]=ME098&stations[]=07627&stations[]=07335&stations[]=ME117&stations[]=000GT&stations[]=000WE&stations[]=0222&stations[]=ME032&stations[]=000PS&stations[]=000LY&stations[]=07661&stations[]=0068&stations[]=0055&stations[]=0151&stations[]=0206&stations[]=ME102&stations[]=000C7&stations[]=000VQ&stations[]=000ZX&stations[]=000CW&stations[]=000TL&stations[]=0037&stations[]=000F3&stations[]=000G2&stations[]=000K2&stations[]=ME119&stations[]=000Z9&stations[]=000Y5&stations[]=000ST&stations[]=000DP&stations[]=000IC&stations[]=000A1&stations[]=ME034&stations[]=07761&stations[]=0182&stations[]=000HH&stations[]=000ZU&stations[]=000NG&stations[]=000RX&stations[]=VENTOUX&stations[]=000BZ&stations[]=ME052&stations[]=000V2&stations[]=00047&stations[]=000XJ&stations[]=000PU&stations[]=0204&stations[]=000V0&stations[]=07110&stations[]=0147&stations[]=000DQ&stations[]=ME011&stations[]=000N3&stations[]=000NM&stations[]=000OM&stations[]=000QT&stations[]=07280&stations[]=000X2&stations[]=000YN&stations[]=000RL&stations[]=0213&stations[]=000AY&stations[]=000RE&stations[]=ME020&stations[]=0069&stations[]=000CT&stations[]=000BV&start=2019-11-29&end=2019-11-30&token=cELguLzjiB2WDGMIacgzE7cXSmAPIw1MlSEi53H68FxA7bhkqFdcA\n",
            "Error decoding CSV: 'pluie_3h'\n",
            "                station_id dh_utc temperature pression humidite  \\\n",
            "                station_id dh_utc        degC      hPa        %   \n",
            "0      2019-11-15 00:00:00    5.2       997.5     92.0      4.0   \n",
            "1      2019-11-15 00:30:00    5.2       997.5     92.0      4.0   \n",
            "2      2019-11-15 01:00:00    5.2       997.6     93.0      4.1   \n",
            "3      2019-11-15 01:30:00    5.1       997.7     93.0      4.1   \n",
            "4      2019-11-15 02:00:00    5.2       997.5     93.0      4.2   \n",
            "...                    ...    ...         ...      ...      ...   \n",
            "44117  2019-11-30 19:00:00   -0.7         NaN      NaN      NaN   \n",
            "44118  2019-11-30 20:00:00   -0.5         NaN      NaN      NaN   \n",
            "44119  2019-11-30 21:00:00   -1.2         NaN      NaN      NaN   \n",
            "44120  2019-11-30 22:00:00   -1.5         NaN      NaN      NaN   \n",
            "44121  2019-11-30 23:00:00   -0.7         NaN      NaN      NaN   \n",
            "\n",
            "      point_de_rosee vent_moyen vent_rafales vent_direction pluie_1h  \n",
            "                degC       km/h         km/h            deg       mm  \n",
            "0                0.0        NaN         76.0            0.0      0.0  \n",
            "1                0.0        NaN         76.0            NaN      NaN  \n",
            "2                0.0        NaN         76.0            0.0      0.4  \n",
            "3                0.0        NaN         76.0            NaN      NaN  \n",
            "4                0.0        NaN         68.0            0.0      0.2  \n",
            "...              ...        ...          ...            ...      ...  \n",
            "44117           91.8       99.7        147.0            NaN      NaN  \n",
            "44118           92.9      101.2        153.0            NaN      NaN  \n",
            "44119           74.9       88.9        143.0            NaN      NaN  \n",
            "44120           86.8      104.4        137.0            NaN      NaN  \n",
            "44121           94.0      112.7        139.0            NaN      NaN  \n",
            "\n",
            "[44122 rows x 10 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Julian\\AppData\\Local\\Temp\\ipykernel_9496\\1021768753.py:26: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
            "  data_df = data_df.drop(columns_to_exclude, axis=1)\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "year = 2019\n",
        "month = 11\n",
        "\n",
        "result_dataframe = get_data_for_month(year, month, api_token, stations)\n",
        "print(result_dataframe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pré-processer les données pour n'avoir des mesures que toutes les heures (au lieu de toutes les 10, 30 minutes etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def pre_process_df(df):\n",
        "    # Convert 'Timestamp' to datetime\n",
        "    df['dh_utc'] = pd.to_datetime(df['dh_utc'], format='%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    # Extract the hour from the timestamp\n",
        "    df['Hour'] = df['dh_utc'].dt.floor('H')  # Round down to the nearest hour\n",
        "\n",
        "    # Group by 'StationID', 'Hour', and aggregate the measurements using mean\n",
        "    aggregated_df = df.groupby(['station_id', 'Hour'], as_index=False).agg({\n",
        "        'temperature': 'mean',\n",
        "        'vent_moyen': 'mean',\n",
        "        'pluie_1h': 'mean'\n",
        "    })\n",
        "\n",
        "    return aggregated_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "to assemble mappings requires at least that [year, month, day] be specified: [day,month,year] is missing",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Julian\\OneDrive\\Desktop\\COURS\\S9\\Projet Big Data\\ProjetBigDataM2-2024\\BigData.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Julian/OneDrive/Desktop/COURS/S9/Projet%20Big%20Data/ProjetBigDataM2-2024/BigData.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m new_incroyable_df \u001b[39m=\u001b[39m pre_process_df(result_dataframe)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Julian/OneDrive/Desktop/COURS/S9/Projet%20Big%20Data/ProjetBigDataM2-2024/BigData.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m display(new_incroyable_df)\n",
            "\u001b[1;32mc:\\Users\\Julian\\OneDrive\\Desktop\\COURS\\S9\\Projet Big Data\\ProjetBigDataM2-2024\\BigData.ipynb Cell 22\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Julian/OneDrive/Desktop/COURS/S9/Projet%20Big%20Data/ProjetBigDataM2-2024/BigData.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpre_process_df\u001b[39m(df):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Julian/OneDrive/Desktop/COURS/S9/Projet%20Big%20Data/ProjetBigDataM2-2024/BigData.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# Convert 'Timestamp' to datetime\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Julian/OneDrive/Desktop/COURS/S9/Projet%20Big%20Data/ProjetBigDataM2-2024/BigData.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mdh_utc\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mto_datetime(df[\u001b[39m'\u001b[39;49m\u001b[39mdh_utc\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mY-\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mm-\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39m \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mH:\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mM:\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mS\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Julian/OneDrive/Desktop/COURS/S9/Projet%20Big%20Data/ProjetBigDataM2-2024/BigData.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# Extract the hour from the timestamp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Julian/OneDrive/Desktop/COURS/S9/Projet%20Big%20Data/ProjetBigDataM2-2024/BigData.ipynb#X42sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mHour\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mdh_utc\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mfloor(\u001b[39m'\u001b[39m\u001b[39mH\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# Round down to the nearest hour\u001b[39;00m\n",
            "File \u001b[1;32me:\\anaconda3\\envs\\aag-talp\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1115\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1113\u001b[0m         result \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39m_constructor(values, index\u001b[39m=\u001b[39marg\u001b[39m.\u001b[39mindex, name\u001b[39m=\u001b[39marg\u001b[39m.\u001b[39mname)\n\u001b[0;32m   1114\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[39m.\u001b[39mMutableMapping)):\n\u001b[1;32m-> 1115\u001b[0m     result \u001b[39m=\u001b[39m _assemble_from_unit_mappings(arg, errors, utc)\n\u001b[0;32m   1116\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, Index):\n\u001b[0;32m   1117\u001b[0m     cache_array \u001b[39m=\u001b[39m _maybe_cache(arg, \u001b[39mformat\u001b[39m, cache, convert_listlike)\n",
            "File \u001b[1;32me:\\anaconda3\\envs\\aag-talp\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1231\u001b[0m, in \u001b[0;36m_assemble_from_unit_mappings\u001b[1;34m(arg, errors, utc)\u001b[0m\n\u001b[0;32m   1229\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(req):\n\u001b[0;32m   1230\u001b[0m     _required \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(req)\n\u001b[1;32m-> 1231\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1232\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mto assemble mappings requires at least that \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1233\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[year, month, day] be specified: [\u001b[39m\u001b[39m{\u001b[39;00m_required\u001b[39m}\u001b[39;00m\u001b[39m] is missing\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1234\u001b[0m     )\n\u001b[0;32m   1236\u001b[0m \u001b[39m# keys we don't recognize\u001b[39;00m\n\u001b[0;32m   1237\u001b[0m excess \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\u001b[39mset\u001b[39m(unit_rev\u001b[39m.\u001b[39mkeys()) \u001b[39m-\u001b[39m \u001b[39mset\u001b[39m(_unit_map\u001b[39m.\u001b[39mvalues()))\n",
            "\u001b[1;31mValueError\u001b[0m: to assemble mappings requires at least that [year, month, day] be specified: [day,month,year] is missing"
          ]
        }
      ],
      "source": [
        "new_incroyable_df = pre_process_df(result_dataframe)\n",
        "display(new_incroyable_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLLs09VDaxZT"
      },
      "outputs": [],
      "source": [
        "# Assuming result_dataframe is your DataFrame\n",
        "result_dataframe.to_csv('output_file.csv', index=False, encoding='utf-8-sig', sep=',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kafka"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Config Kafka"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {}\n",
        "# Required connection configs for Kafka producer, consumer, and admin\n",
        "config[\"bootstrap.servers\"] = \"pkc-60py3.europe-west9.gcp.confluent.cloud:9092\"\n",
        "#bootstrap.servers=pkc-60py3.europe-west9.gcp.confluent.cloud:9092\n",
        "config[\"security.protocol\"] = \"SASL_SSL\"\n",
        "#security.protocol=SASL_SSL\n",
        "config[\"sasl.mechanisms\"] = \"PLAIN\"\n",
        "#sasl.mechanisms=PLAIN\n",
        "config[\"sasl.username\"] = \"2WQXJOQPDG2MWLJB\"\n",
        "#sasl.username=2WQXJOQPDG2MWLJB\n",
        "config[\"sasl.password\"] = \"N0wpBXjhU3cBEawVm5aX5Ql5IofNTvWf4+CEHQgz+F2sinER5J/p6OJZpFJs0Hd5\"\n",
        "#sasl.password=N0wpBXjhU3cBEawVm5aX5Ql5IofNTvWf4+CEHQgz+F2sinER5J/p6OJZpFJs0Hd5\n",
        "\n",
        "# Best practice for higher availability in librdkafka clients prior to 1.7\n",
        "config[\"session.timeout.ms\"] = \"45000\"\n",
        "#session.timeout.ms=45000\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Required connection configs for Confluent Cloud Schema Registry\n",
        "schema.registry.url=https://psrc-j55zm.us-central1.gcp.confluent.cloud\n",
        "basic.auth.credentials.source=USER_INFO\n",
        "basic.auth.user.info={{ SR_API_KEY }}:{{ SR_API_SECRET }}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Producer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "producer = ck.Producer(config)\n",
        "producer.produce(\"mon_topic_demo\", key=\"test\", value=\"Fuck la co de la fack\")\n",
        "producer.poll(1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
